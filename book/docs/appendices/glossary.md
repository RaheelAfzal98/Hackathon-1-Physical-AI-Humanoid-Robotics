# Glossary

This glossary contains important terms used throughout the Physical AI & Humanoid Robotics textbook.

## A

**Action**: In ROS 2, a communication pattern for long-running tasks with feedback and status updates.

**AI (Artificial Intelligence)**: The simulation of human intelligence processes by machines, especially computer systems.

## B

**Behavior Tree**: A decision-making model used in robotics and AI to structure the logic of autonomous agents.

## C

**Codecs (Coder-Decoder)**: Algorithms for encoding and decoding data, often used in video and audio processing.

**Computer Vision**: A field of artificial intelligence that trains computers to interpret and understand visual information from the world.

## D

**Digital Twin**: A virtual representation of a physical system that mirrors the physical object throughout its lifecycle.

## E

**Embodiment**: The concept of artificial intelligence existing in a physical form, allowing interaction with the real world.

## F

**Forward Kinematics**: The use of joint parameters to compute the position and orientation of the end-effector.

## G

**Gazebo**: A physics-based 3D simulation environment often used in robotics research and development.

## H

**Human-Robot Interaction (HRI)**: The study of interactions between humans and robots.

## I

**Inverse Kinematics**: The mathematical process of determining joint parameters that achieve a desired end-effector position.

**Intentional Behavior**: Actions performed by a robot with a specific goal or purpose in mind.

## J

**Joint**: A connection between two or more links in a robotic mechanism that allows relative motion.

## K

**Kinematics**: The study of motion without considering the forces that cause the motion.

## L

**LIDAR (Light Detection and Ranging)**: A remote sensing method that uses light in the form of a pulsed laser to measure distances.

**LLM (Large Language Model)**: A type of artificial intelligence model designed to understand and generate human language.

## M

**Motion Planning**: The computational problem of planning a sequence of movements for a robot to reach a goal while avoiding obstacles.

## N

**Navigation**: The ability of a robot to move through its environment from one location to another.

**Neural Network**: A series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics how the human brain operates.

## O

**Obstacle Avoidance**: Algorithms and techniques used by robots to detect and avoid obstacles in their environment.

## P

**Path Planning**: The process of determining a route from a start to a goal that avoids obstacles.

**Perception**: The ability of a robot to gather and interpret sensory information about its environment.

## Q

**Q-learning**: A model-free reinforcement learning algorithm to learn quality of actions telling an agent what action to take under what circumstances.

## R

**Robot Operating System (ROS)**: A flexible framework for writing robot software that provides services designed for a heterogeneous computer cluster.

**ROS 2**: The second generation of the Robot Operating System with improved features like out-of-the-box support for multi-robot systems and deployment to production environments.

## S

**SLAM (Simultaneous Localization and Mapping)**: The computational problem of constructing or updating a map of an unknown environment while simultaneously keeping track of an agent's location within it.

**State Machine**: A computational model of a system that can be in one of a finite number of states at any given time.

**Supervised Learning**: A type of machine learning where the model is trained on input-output pairs.

## T

**Teleoperation**: The remote control of a robot by a human operator.

**Trajectory**: A time-ordered sequence of position, orientation, and other state parameters that define the path of a moving object.

## U

**URDF (Unified Robot Description Format)**: An XML format for representing a robot model including its links, joints, and other properties.

## V

**Vision-Language-Action (VLA)**: A system that integrates visual perception, language understanding, and physical action for intelligent robot behavior.

**VSLAM (Visual Simultaneous Localization and Mapping)**: SLAM using visual sensors instead of or in addition to other sensor types.

## W

**Waypoint**: A reference point along a route or path used for navigation.

## X, Y, Z

**These letters are used to denote axes in 3D coordinate systems**:

- X: typically forward/backward axis
- Y: typically left/right axis  
- Z: typically up/down axis